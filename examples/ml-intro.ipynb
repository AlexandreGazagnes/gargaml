{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gargaml\n",
    "from gargaml import *\n",
    "from gargaml import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y  = Data().Load.titanic(True, precleaning=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue=\"survived\", corner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(df, x=\"survived\", y=\"fare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(df, x=\"survived\", y=\"pclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(df, x=\"survived\", y=\"age\", color=\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=\"passengerid\", inplace=True)\n",
    "X.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # viert pret à 0\n",
    "\n",
    "\n",
    "\n",
    "# # virer total amont/anuity  / target => NAN\n",
    "# # virer total amont/anuity  => 0 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # feat eng.\n",
    "# df_amout_rate = df.toal_amount / df.annuity\n",
    "# df_salary_rate = df.toal_amount / df.salary \n",
    "# df_annuity_rate =  df.annuity / df.Salary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"fare_by_age\"] = X.fare/ X.age\n",
    "X[\"fare_by_pclass\"] = X.fare/X.pclass \n",
    "X[\"fare_null\"] = (X.fare == 0).astype(int)\n",
    "X[\"age_is_nan\"] = X.age.isna().astype(int)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = EllipticEnvelope()\n",
    "tmp = X.select_dtypes(np.number)\n",
    "tmp =KNNImputer().fit_transform(tmp)\n",
    "ee = detector.fit_predict(tmp)\n",
    "ee = pd.Series(ee, name=\"is_outlier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.value_counts(normalize=True).round(2\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = ee.apply(lambda i : False if i==1 else True)\n",
    "ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"algorithmic_outlier\"] = ee.values.astype(int)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = X.copy()\n",
    "X_1.describe().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X.loc[~ee.values]\n",
    "X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.describe().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().mean().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer()\n",
    "\n",
    "cols = X_train.select_dtypes(include=np.number).columns\n",
    "display(cols)\n",
    "\n",
    "imputer.fit(X_train.select_dtypes(include=np.number))\n",
    "X_train = imputer.transform(X_train.select_dtypes(include=np.number))\n",
    "\n",
    "# X_train = imputer.fit_transform(X_train.select_dtypes(include=np.number))\n",
    "X_test = imputer.transform(X_test.select_dtypes(include=np.number))\n",
    "X_train\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=cols)\n",
    "X_test = pd.DataFrame(X_test, columns=cols)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier()\n",
    "# estimator = LogisticRegression()\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = estimator.predict(X_train)\n",
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.score(X_train, y_train).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.score(X_test, y_test).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[0]\n",
    "p0 = X_train.iloc[0]\n",
    "p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.predict(p0.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.predict(p0.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>fare_by_age</th>\n",
       "      <th>fare_by_pclass</th>\n",
       "      <th>fare_null</th>\n",
       "      <th>age_is_nan</th>\n",
       "      <th>algorithmic_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.635048</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  pclass   age  sibsp  parch  fare  fare_by_age  fare_by_pclass   \n",
       "0        271.0     1.0  20.4    0.0    0.0  31.0     3.635048            31.0  \\\n",
       "\n",
       "   fare_null  age_is_nan  algorithmic_outlier  \n",
       "0        0.0         1.0                  0.0  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = X_train.iloc[:1]\n",
    "p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86, 0.14])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_p0 = estimator.predict_proba(p0)\n",
    "pred_p0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feat_importance \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(estimator\u001b[39m.\u001b[39;49mcoef_[\u001b[39m0\u001b[39m], index\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m      2\u001b[0m feat_importance\u001b[39m.\u001b[39mround(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msort_values(ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "feat_importance = pd.Series(estimator.coef_[0], index=X_train.columns)\n",
    "feat_importance.round(2).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'intercept_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[186], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m estimator\u001b[39m.\u001b[39;49mintercept_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'intercept_'"
     ]
    }
   ],
   "source": [
    "estimator.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passengerid            0.20\n",
       "fare_by_age            0.19\n",
       "age                    0.16\n",
       "fare_by_pclass         0.16\n",
       "fare                   0.14\n",
       "pclass                 0.06\n",
       "sibsp                  0.04\n",
       "parch                  0.03\n",
       "age_is_nan             0.02\n",
       "algorithmic_outlier    0.01\n",
       "fare_null              0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance = pd.Series(estimator.feature_importances_, index=X_train.columns)\n",
    "feat_importance = feat_importance.round(2).sort_values(ascending=False)\n",
    "feat_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passengerid': 0.2,\n",
       " 'fare_by_age': 0.19,\n",
       " 'age': 0.16,\n",
       " 'fare_by_pclass': 0.16,\n",
       " 'fare': 0.14,\n",
       " 'pclass': 0.06,\n",
       " 'sibsp': 0.04,\n",
       " 'parch': 0.03,\n",
       " 'age_is_nan': 0.02,\n",
       " 'algorithmic_outlier': 0.01,\n",
       " 'fare_null': 0.0}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>fare_by_age</th>\n",
       "      <th>fare_by_pclass</th>\n",
       "      <th>fare_null</th>\n",
       "      <th>age_is_nan</th>\n",
       "      <th>algorithmic_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.635048</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  pclass   age  sibsp  parch  fare  fare_by_age  fare_by_pclass   \n",
       "0        271.0     1.0  20.4    0.0    0.0  31.0     3.635048            31.0  \\\n",
       "\n",
       "   fare_null  age_is_nan  algorithmic_outlier  \n",
       "0        0.0         1.0                  0.0  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[199], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m shap_values \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mshap_values(X_train\u001b[39m.\u001b[39;49miloc[:\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/gargaml/env/lib/python3.10/site-packages/shap/explainers/_tree.py:384\u001b[0m, in \u001b[0;36mTree.shap_values\u001b[0;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massert_additivity(out, model_output_vals)\n\u001b[1;32m    382\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m--> 384\u001b[0m X, y, X_missing, flat_output, tree_limit, check_additivity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_inputs(X, y,\n\u001b[1;32m    385\u001b[0m                                                                                    tree_limit,\n\u001b[1;32m    386\u001b[0m                                                                                    check_additivity)\n\u001b[1;32m    387\u001b[0m transform \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_transform()\n\u001b[1;32m    389\u001b[0m \u001b[39m# run the core algorithm using the C extension\u001b[39;00m\n",
      "File \u001b[0;32m~/gargaml/env/lib/python3.10/site-packages/shap/explainers/_tree.py:250\u001b[0m, in \u001b[0;36mTree._validate_inputs\u001b[0;34m(self, X, y, tree_limit, check_additivity)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39minput_dtype:\n\u001b[1;32m    249\u001b[0m     X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mastype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39minput_dtype)\n\u001b[0;32m--> 250\u001b[0m X_missing \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misnan(X, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mbool)\n\u001b[1;32m    251\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(X, np\u001b[39m.\u001b[39mndarray), \u001b[39m\"\u001b[39m\u001b[39mUnknown instance type: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(X))\n\u001b[1;32m    252\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(X\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPassed input data matrix X must have 1 or 2 dimensions!\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/gargaml/env/lib/python3.10/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "shap_values = explainer.shap_values(X_train.iloc[:1])\n",
    "# shap_values ==> comprenne la structure de cette objet\n",
    "# [0 {} , 1 {}] ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Chaque point => ROUTE\n",
    "\n",
    "1 / regle le pb de predict / predict proba \n",
    "2 / Comprenne objet de shap values ==> fabriquer un dictionnaire => envoyer depuis api (json)\n",
    "3 / Route descibre => X_train.mean().to_dict() => route\n",
    "\n",
    "==> derniere partie de API ==> METTRE API \"en ligne\" ==> heroku ==> git / git hub (logiciel qui héberge le code)\n",
    "\n",
    "NE PRENDS QUE 10 % de daats => SI API avec 100 lignes (cest ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  # QuantileTransformer(n_quantiles=100)\n",
    "# scaler = MinMaxScaler()  # QuantileTransformer(n_quantiles=100)\n",
    "\n",
    "# scaler.fit(X_train)\n",
    "# X_train_sca = scaler.transform(X_train)\n",
    "X_train_sca = scaler.fit_transform(X_train)\n",
    "X_test_sca = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sca = pd.DataFrame(X_train_sca, columns=cols)\n",
    "X_test_sca = pd.DataFrame(X_test_sca, columns=cols)\n",
    "X_train_sca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sca.describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "estimator = LinearRegression()\n",
    "estimator.fit(X_train_sca, y_train)\n",
    "\n",
    "display(estimator.score(X_train_sca, y_train).round(2))\n",
    "display(estimator.score(X_test_sca, y_test).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = LogisticRegression()\n",
    "# estimator.fit(X_train_sca, y_train)\n",
    "\n",
    "# display(estimator.score(X_train_sca, np.log1p(y_train).astype(int)))\n",
    "# display(estimator.score(X_test_sca, np.log1p(y_test).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.log1p(y_train).astype(int).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    {},\n",
    "    cv=10, # StratifiedShuffleSplit(n_splits=10, test_size=0.3)\n",
    "    n_jobs=4,\n",
    "    verbose=2,\n",
    "    return_train_score=True,\n",
    ")\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid.score(X_train, y_train))\n",
    "display(grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid.best_estimator_.score(X_train, y_train))\n",
    "display(grid.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(grid.cv_results_).round(2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [i for i in res.columns if \"split\" not in i]\n",
    "res = res.loc[:, cols]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultize(grid):\n",
    "    \"\"\"from a fited grid search build / return a fancy dataframe of results\"\"\"\n",
    "\n",
    "    res = pd.DataFrame(grid.cv_results_).round(2)\n",
    "    cols = [i for i in res.columns if \"split\" not in i]\n",
    "    res = res.loc[:, cols]\n",
    "\n",
    "    res = res.sort_values(\"mean_test_score\", ascending=False)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blabla = resultize(grid)\n",
    "blabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        # (\"sampler\", RandomUnderSampler()),\n",
    "        (\"imputer\", KNNImputer()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"estimator\", LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, {}, cv=10, n_jobs=-1, verbose=2, return_train_score=True)\n",
    "grid.fit(X.select_dtypes(include=np.number), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [\n",
    "    # (\"sampler\", RandomUnderSampler()),\n",
    "    (\"imputer\", KNNImputer()),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"estimator\", LogisticRegression()),\n",
    "]\n",
    "\n",
    "pipe = Pipeline(\n",
    "    li\n",
    ")\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "\n",
    "\n",
    "    # \"estimator\": [LogisticRegression()],\n",
    "    \n",
    "\n",
    "\n",
    "    # \"sampler\": [\"passthrough\", RandomUnderSampler()],\n",
    "    \n",
    "    \"imputer\": [\n",
    "        KNNImputer(),\n",
    "        SimpleImputer(strategy=\"mean\"),\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "    ],\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cv():\n",
    "#     return StratifiedShuffleSplit(n_splits=10, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = -1\n",
    "VERBOSE = 1\n",
    "CV = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=CV,\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=VERBOSE,\n",
    "    return_train_score=True,\n",
    ")\n",
    "grid.fit(X.select_dtypes(include=np.number), y)\n",
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"estimator\": [LogisticRegression(), ], # RandomForestClassifier()\n",
    "    #\n",
    "\n",
    "    # \"sampler\": [\"passthrough\", RandomUnderSampler()],\n",
    "    \n",
    "    \"imputer\": [KNNImputer(), SimpleImputer()],\n",
    "    \n",
    "    \"scaler\": [\n",
    "        StandardScaler(),\n",
    "        Normalizer(),\n",
    "        QuantileTransformer(n_quantiles=100),\n",
    "        MinMaxScaler(),\n",
    "        \"passthrough\",\n",
    "    ],\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=CV,\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=VERBOSE,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "grid.fit(X.select_dtypes(include=np.number), y)\n",
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    # \"imputer\"  : [KNNImputer(), SimpleImputer()],\n",
    "    # \"scaler\" : [StandardScaler(), Normalizer(), QuantileTransformer(n_quantiles=100), \"passthrough\"],  # MinMaxScaler()\n",
    "    \"estimator\": [\n",
    "        DummyClassifier(),\n",
    "        LogisticRegression(),\n",
    "        KNeighborsClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "    ]\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe, param_grid=param_grid, cv=CV, n_jobs=-1, verbose=1, return_train_score=True\n",
    ")\n",
    "grid.fit(X.select_dtypes(include=np.number), y)\n",
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \n",
    "    # \"sampler\": [\"passthrough\", RandomUnderSampler()],\n",
    "\n",
    "    \"imputer\": [KNNImputer(), SimpleImputer()],\n",
    "\n",
    "    \"scaler\": [\n",
    "        StandardScaler(),\n",
    "        Normalizer(),\n",
    "        QuantileTransformer(n_quantiles=100),\n",
    "        \"passthrough\",\n",
    "    ],  # MinMaxScaler()\n",
    "    \n",
    "    \"estimator\": [\n",
    "        LogisticRegression(),\n",
    "        KNeighborsClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "    ],  # DummyClassifier()\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=CV,\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=VERBOSE,\n",
    "    return_train_score=True,\n",
    ")\n",
    "grid.fit(X.select_dtypes(include=np.number), y)\n",
    "resultize(grid).sort_values(\"mean_test_score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultize(grid).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=CV,\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=VERBOSE,\n",
    "    return_train_score=True,\n",
    ")\n",
    "grid.fit(pd.get_dummies(X), y)\n",
    "resultize(grid).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"sampler\": [\n",
    "        \"passthrough\",\n",
    "    ],  # RandomUnderSampler()\n",
    "    \"imputer\": [\n",
    "        KNNImputer(),\n",
    "    ],\n",
    "    \"scaler\": [\n",
    "        StandardScaler(),\n",
    "        Normalizer(),\n",
    "        QuantileTransformer(n_quantiles=100),\n",
    "        \"passthrough\",\n",
    "    ],\n",
    "    \"estimator\": [\n",
    "        KNeighborsClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        XGBClassifier(),\n",
    "    ],  # LogisticRegression(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv(),\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=VERBOSE,\n",
    "    return_train_score=True,\n",
    ")\n",
    "grid.fit(pd.get_dummies(X), y)\n",
    "resultize(grid).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    # \"sampler\": [\n",
    "    #     \"passthrough\",\n",
    "    # ],  # RandomUnderSampler()\n",
    "    \"imputer\": [\n",
    "        KNNImputer(),\n",
    "    ],\n",
    "    \"scaler\": [\n",
    "        StandardScaler(),\n",
    "        Normalizer(),\n",
    "        QuantileTransformer(n_quantiles=100),\n",
    "        \"passthrough\",\n",
    "    ],\n",
    "    \"estimator\": [\n",
    "        KNeighborsClassifier(),\n",
    "    ],  # LogisticRegression(),\n",
    "\n",
    "    \"estimator__n_neighbors\" : [3, 5, 7, 10, 15, 20],\n",
    "    \"imputer__n_neighbors\" :  [3, 5, 7, 10, 15, 20],\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=CV,\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=VERBOSE,\n",
    "    return_train_score=True,\n",
    ")\n",
    "grid.fit(pd.get_dummies(X), y)\n",
    "resultize(grid).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(X.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.age.skew().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.fare.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(X.sibsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.select_dtypes(np.number).columns : \n",
    "    \n",
    "    txt = f\"{col} ==> {X[col].skew():.2f}\"\n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY = False \n",
    "\n",
    "if DISPLAY : \n",
    "    sns.pairplot(X, corner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(X.fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(np.log1p(X.fare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"equipage\"] = (X.fare ==0).astype(int)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X.equipage == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transf = X.copy()\n",
    "X_transf[\"fare\"] = np.log1p(X_transf[\"fare\"])\n",
    "X_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transf[\"sex\"] = X_transf[\"sex\"].apply(lambda i : 1 if i ==\"male\" else 0)\n",
    "X_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"sampler\": [\n",
    "        \"passthrough\",\n",
    "    ],  # RandomUnderSampler()\n",
    "    \"imputer\": [\n",
    "        KNNImputer(),\n",
    "    ],\n",
    "    \"scaler\": [\n",
    "        StandardScaler(),\n",
    "        Normalizer(),\n",
    "        QuantileTransformer(n_quantiles=100),\n",
    "        \"passthrough\",\n",
    "    ],\n",
    "    \"estimator\": [\n",
    "        XGBClassifier(), \n",
    "        RandomForestClassifier(), \n",
    "        KNeighborsClassifier(),\n",
    "    ],  # LogisticRegression(),\n",
    "\n",
    "    # \"estimator__n_neighbors\" : [3, 5, 7, 10, 15, 20],\n",
    "    # \"imputer__n_neighbors\" :  [3, 5, 7, 10, 15, 20],\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv(),\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=VERBOSE,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "grid.fit(pd.get_dummies(X), y)\n",
    "resultize(grid).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv(),\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=VERBOSE,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "grid.fit(pd.get_dummies(X_transf), y)\n",
    "resultize(grid).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultize(grid, log_target=0, transf=0, features=\"\"):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    res = pd.DataFrame(grid.cv_results_).round(2)\n",
    "    cols = [i for i in res.columns if \"split\" not in i]\n",
    "    res = res.loc[:, cols]\n",
    "\n",
    "    ######################\n",
    "    ######################\n",
    "\n",
    "    res[\"log_target\"] = log_target\n",
    "    res[\"transf\"] = transf\n",
    "    res[\"features\"] = features\n",
    "\n",
    "    ######################\n",
    "    ######################\n",
    "\n",
    "    return res.sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=CV,\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=VERBOSE,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "grid.fit(pd.get_dummies(X), y)\n",
    "res = resultize(grid, log_target=0, transf=0, features=\"dummies\")\n",
    "\n",
    "\n",
    "RES = pd.concat([RES, res], axis=0, ignore_index=True)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES.iloc[:, -3:].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv(),\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=VERBOSE,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "grid.fit(pd.get_dummies(X_transf), y)\n",
    "res = resultize(grid, log_target=0, transf=0, features=\"dummies\")\n",
    "\n",
    "\n",
    "RES = pd.concat([RES, res], axis=0, ignore_index=True)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe, param_grid=param_grid, cv=10, n_jobs=-1, verbose=1, return_train_score=True\n",
    ")\n",
    "grid.fit(X.select_dtypes(include=np.number), y)\n",
    "\n",
    "res = resultize(grid, log_target=0, transf_fare=0, features=\"only_num\")\n",
    "\n",
    "\n",
    "RES = pd.concat([RES, res], axis=0, ignore_index=True)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = GridSearchCV(\n",
    "#     pipe, param_grid=param_grid, cv=10, n_jobs=-1, verbose=1, return_train_score=True\n",
    "# )\n",
    "# _y = np.log1p(y).astype(int)\n",
    "# grid.fit(X.select_dtypes(include=np.number), _y)\n",
    "\n",
    "# res = resultize(grid, log_target=1, transf_fare=0, features=\"only_num\")\n",
    "\n",
    "\n",
    "# RES = pd.concat([RES, res], axis=0, ignore_index=True)\n",
    "# res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES.iloc[:, -3:].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES.transf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier()\tKNNImputer()\t\"passthrough\"  \"0\"\t\"1\"\t\"dummies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipe = Pipeline(\n",
    "    [    \n",
    "        # (\"sampler\", RandomUnderSampler()),\n",
    "        # (\"selector\", ColumnSelector(threshold=0.33)),\n",
    "        # (\"preprocessor\", preprocessor),\n",
    "        (\"imputer\", KNNImputer()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"reductor\", PCA()), \n",
    "        (\"estimator\", LogisticRegression()),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    # \"sampler\": [\n",
    "    #     \"passthrough\",\n",
    "    # ],  # RandomUnderSampler()\n",
    "\n",
    "    \"imputer\": [\n",
    "        KNNImputer()\n",
    "    ],\n",
    "\n",
    "    \"reductor\": [PCA(svd_solver = 'full')],\n",
    "\n",
    "    \"scaler\": [\n",
    "        StandardScaler(),\n",
    "        QuantileTransformer(n_quantiles=100),\n",
    "        \"passthrough\",\n",
    "    ],         # Normalizer(),\n",
    "\n",
    "    \"estimator\": [\n",
    "        # XGBClassifier(), \n",
    "        # RandomForestClassifier(), \n",
    "        KNeighborsClassifier(),\n",
    "    ],  # LogisticRegression(),\n",
    "\n",
    "    \"reductor__n_components\" :    [0.85, 0.9, 0.95, 0.99], # 0.5, 0.7, 0.8\n",
    "\n",
    "    \"estimator__n_neighbors\" : [3, 5, 7, 10, 15, 20],\n",
    "    # \"imputer__n_neighbors\" :  [3, 5, 7, 10, 15, 20],\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pca_pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=10,\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=VERBOSE,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "grid.fit(pd.get_dummies(X), y)\n",
    "res = resultize(grid, log_target=0, transf=0, features=\"dummies\")\n",
    "RES = pd.concat([RES, res], axis=0, ignore_index=True)\n",
    "display(res.head())\n",
    "\n",
    "grid.fit(pd.get_dummies(X_transf), y)\n",
    "res = resultize(grid, log_target=0, transf=1, features=\"dummies\")\n",
    "RES = pd.concat([RES, res], axis=0, ignore_index=True)\n",
    "\n",
    "display(res.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     \"estimator__n_estimators\": [100, 150, 200, 300, 400, 500],\n",
    "#     \"imputer\": [\n",
    "#         KNNImputer(),\n",
    "#     ],\n",
    "#     \"scaler\": [\n",
    "#         \"passthrough\",\n",
    "#     ],\n",
    "#     \"estimator\": [\n",
    "#         RandomForestClassifier(),\n",
    "#     ],\n",
    "# }\n",
    "# param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipe, param_grid=param_grid, cv=10, n_jobs=-1, verbose=1, return_train_score=True\n",
    ")\n",
    "grid.fit(X.select_dtypes(include=np.number), y)\n",
    "res = resultize(grid, log_target=0, transf=0, features=\"only_num\")\n",
    "RES = pd.concat([RES, res], axis=0, ignore_index=True)\n",
    "display(res.head())\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe, param_grid=param_grid, cv=10, n_jobs=-1, verbose=1, return_train_score=True\n",
    ")\n",
    "grid.fit(pd.get_dummies(X), y)\n",
    "res = resultize(grid, log_target=0, transf=0, features=\"dummies\")\n",
    "RES = pd.concat([RES, res], axis=0, ignore_index=True)\n",
    "display(res.head())\n",
    "\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe, param_grid=param_grid, cv=10, n_jobs=-1, verbose=1, return_train_score=True\n",
    ")\n",
    "grid.fit(X_transf.select_dtypes(include=np.number), y)\n",
    "res = resultize(grid, log_target=0, transf=1, features=\"only_num\")\n",
    "RES = pd.concat([RES, res], axis=0, ignore_index=True)\n",
    "display(res.head())\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe, param_grid=param_grid, cv=10, n_jobs=-1, verbose=1, return_train_score=True\n",
    ")\n",
    "grid.fit(pd.get_dummies(X_transf), y)\n",
    "res = resultize(grid, log_target=0, transf=1, features=\"dummies\")\n",
    "RES = pd.concat([RES, res], axis=0, ignore_index=True)\n",
    "display(res.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES = RES.loc[RES.log_target == 0]\n",
    "RES.sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Data.Load.food(False)\n",
    "DF = df.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.product_name = df.product_name.fillna(\"unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.loc[df.product_name.str.lower().str.contains(\"nutell\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['energy_100g', 'fat_100g',\n",
    "       'saturated-fat_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g',\n",
    "       'proteins_100g', 'salt_100g', 'sodium_100g', ]\n",
    "df = df.dropna(axis=0, how=\"all\", subset=cols)\n",
    "\n",
    "\n",
    "cols = [\"product_name\", 'additives_n', \n",
    "'ingredients_from_palm_oil_n', 'nutrition_grade_fr', 'pnns_groups_1',\n",
    "'energy_100g', 'fat_100g',\n",
    "'saturated-fat_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g',\n",
    "'proteins_100g', 'salt_100g', 'nutrition-score-fr_100g', ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.product_name = df.product_name.fillna(\"unknown\")\n",
    "df = df.loc[:, cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.product_name.str.lower().str.contains(\"nutell\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df.iloc[:, -9:-1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = SimpleImputer(strategy=\"median\").fit_transform(x)\n",
    "ee = EllipticEnvelope().fit_predict(x)\n",
    "# pd.Series(ee).value_counts()\n",
    "\n",
    "\n",
    "ee= [True if i == 1 else False for i in ee ]\n",
    "pd.Series(ee).value_counts().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[ ee , :  ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = df.loc[df.nutrition_grade_fr.notna()]\n",
    "norm.describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nutrition_grade_fr  = df.nutrition_grade_fr.fillna('zz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df.copy()\n",
    "_df = _df.sort_values(\"nutrition_grade_fr\")\n",
    "_df[\"is_zz\"]= _df.nutrition_grade_fr==\"zz\"\n",
    "\n",
    "px.box(_df, x=\"pnns_groups_1\", y =\"energy_100g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "px.box(_df, x=\"is_zz\", y =\"energy_100g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(_df, x=\"is_zz\", y =\"sugars_100g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(_df, x=\"is_zz\", y =\"fat_100g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(_df, color=\"is_zz\", y =\"energy_100g\" ,x=\"pnns_groups_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(_df, color=\"is_zz\", y =\"sugars_100g\" ,x=\"pnns_groups_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(_df, color=\"is_zz\", y =\"fat_100g\" ,x=\"pnns_groups_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(_df, color=\"is_zz\", y =\"sugars_100g\" ,x=\"pnns_groups_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(_df, x=\"nutrition_grade_fr\", y =\"fat_100g\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df.loc[df.nutrition_grade_fr.notna()]\n",
    "_df = _df.sort_values(\"nutrition_grade_fr\")\n",
    "px.box(_df, x=\"nutrition_grade_fr\", y =\"fat_100g\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.product_name = df.product_name.fillna(\"unknown\")\n",
    "\n",
    "# df.product_name = df.product_name.apply(clean)\n",
    "# df.product_name = df.product_name.apply(lambda i : i.lower())\n",
    "df.product_name = df.product_name.str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df.copy()\n",
    "\n",
    "_df = _df.loc[df.product_name.str.startswith(\"huile\"), :]\n",
    "_df = _df.loc[df.product_name.str.contains(\"olive\"), :]\n",
    "\n",
    "_df = _df.loc[_df.energy_100g.notna()]\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = _df.loc[_df.energy_100g.notna()\n",
    "              ]\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(_df.energy_100g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"age\", \"fare\"]\n",
    "categorical_features = [\"embarked\", \"sex\", \"pclass\"]\n",
    "\n",
    "\n",
    "# numeric_transformer = Pipeline(\n",
    "#     steps=[(\"imputer\", KNNImputer()), \n",
    "#            (\"scaler\", StandardScaler())]\n",
    "# )\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"passthrough\", \"passthrough\"), \n",
    "        #    (\"scaler\", StandardScaler()), \n",
    "           ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        # (\"selector\", SelectPercentile(chi2, percentile=50)),\n",
    "    ]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        # (\"sampler\", RandomUnderSampler()),\n",
    "        (\"preprocessor\", preprocessor)\n",
    "        (\"imputer\", KNNImputer()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"estimator\", LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y \n",
    "y_log\n",
    "\n",
    "X_log  = mis au log certains features =)=> \n",
    "X_raw =  ans log feats\n",
    "\n",
    "\n",
    "1 / modeles + simple > compiqué \n",
    "\n",
    "    * dummy \n",
    "    * regreslion lineaire que numérique pourie  (baseline )\n",
    "    * gtravailler sur pipes diiférents / estifmateurs metatprametre y log sans log X raw X log \n",
    "    ==> 1 OU plusieurs modeles performats\n",
    "\n",
    "\n",
    "2/ impact energy star score\n",
    "    la version ou tu jette Energy star SCORERS\n",
    "    La verison ou tu gardes enrgy star socre (==> KNNIMPUTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / modeles + simple > compiqué \n",
    "\n",
    "    * dummy \n",
    "    * regreslion lineaire que numérique pourie  (baseline )\n",
    "    * gtravailler sur pipes diiférents / estifmateurs metatprametre y log sans log X raw X log \n",
    "    ==> 1 OU plusieurs modeles performats\n",
    "\n",
    "\n",
    "2/ impact energy star score\n",
    "    la version ou tu jette Energy star SCORERS\n",
    "    La verison ou tu gardes enrgy star socre (==> KNNIMPUTER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90888629e184d1d83dcac18ada7cfabe6087e4d52330dcc8dcea5972745896aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
